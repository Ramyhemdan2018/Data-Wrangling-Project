{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Details\n",
    "## Data wrangling, which consists of:\n",
    "\n",
    "#### Gathering data\n",
    "\n",
    "##### From 'twitter-archive-enhanced.csv' file.\n",
    "\n",
    "##### From a link.\n",
    "\n",
    "##### From twitter API.\n",
    "\n",
    "#### Assessing data\n",
    "\n",
    "#### Cleaning data\n",
    "\n",
    "#### Storing, analyzing, and visualizing your wrangled data\n",
    "\n",
    "#### Reporting on data wrangling efforts.\n",
    "\n",
    "#### The data analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import os\n",
    "import io\n",
    "from twitter_api import get_twitter_data\n",
    "import json\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn --upgrade #or also !pip install seaborn==0.9.0\n",
    "import seaborn as sns\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load twitter archive file into pandas df.\n",
    "df_arch = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download image_predictions file.\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "with open('image_predictions.tsv', mode ='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading TSV file\n",
    "image_prediction = pd.read_csv('image_predictions.tsv', sep='\\t' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data from twitter API \n",
    "if not os.path.exists('tweet_json.txt'):\n",
    "    get_twitter_data(df_arch, 'tweet_json.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tweets data into pandas df\n",
    "with open('tweet_json.txt') as file:\n",
    "    df_api = pd.read_json(file, lines= True, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce df_api to the necessary columns\n",
    "df_json = df_api[['id', 'retweet_count', 'favorite_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_json.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch[['rating_numerator', 'rating_denominator']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch[df_arch.name.str.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for numerators with wrong values in chunks\n",
    "df_arch[df_arch.rating_numerator <= 5].loc[0:1000, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch[df_arch.rating_numerator <= 5].loc[1000:2000, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch[df_arch.rating_numerator <= 5].loc[2000:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.img_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.p1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any records in df_arch are retweets\n",
    "len(df_arch[df_arch.retweeted_status_id.isnull() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by rating_denominator values\n",
    "df_arch.rating_denominator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by rating_numerator values\n",
    "df_arch.rating_numerator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch[['rating_numerator', 'rating_denominator']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch.name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "The following observations were made visually using Excel to view the data and Programmaticly using pandas functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0877cc size=4>**df_arch**</font>\n",
    "1. Columns (`doggo`, `floofer`, `pupper`, `puppo`) has `None` for missing values.\n",
    "2. `source` column is html tag `<a>` we can extract the source of the tweet and covert it to categorical.\n",
    "3. `text` column has the link for the tweets and ratings at the end we can remove it.\n",
    "4. `timestamp` column is `str` instead of `datetime`\n",
    "5. We are interested in the tweet ONLY not the retweet there for we should remove those from the table.\n",
    "6. We are interested in the tweet ONLY not the reply to the original tweet there for we should remove those from the table.\n",
    "7. The `rating_numerator` column should of type `float` and also it should be correctly extracted.\n",
    "8. `rating_denominator` column has values less than 10 and values more than 10 for ratings more than one dog.\n",
    "9. `expanded_urls` column has NaN values\n",
    "10. `id` column in df_api name different than the other 2 data sets.\n",
    "11. `name` column have None instead of NaN and too many unvalid values.\n",
    "12. ID variables are sometimes integers or floats (numeric)\n",
    "13. \"in_reply_to...\" and \"retweeted_status...\" variables are numeric\n",
    "14. retweets are present in the data\n",
    "15. some of the column names are not  meaningful\n",
    "16. \"timestamp\" and \"retweeted_status_timestamp\" are not a datetime variable\n",
    "17. \"source\" values are formatted as <a> href=url </a>\n",
    "18. rating_numerators are not always correctly accounting for decimals\n",
    "19. the dog names are not standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure (Tidiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0877cc size=4>**df_arch**</font>\n",
    "- `doggo`, `floofer`, `pupper`, `puppo` columns are all about the same things, a kind of dog personality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0877cc size=4>**image_prediction**</font>\n",
    "- `img_num` useless.\n",
    "- the columns (`p1`, `p1_dog`, `p1_conf`, ...etc) should be just `breed` and `confidence`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0877cc size=4>**df_api**</font>\n",
    "- Just 3 columns needed `id`, `retweet_count`, `favorite_count`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0877cc size=4>**In General**</font>\n",
    "- All datasets should be combined into 1 dataset only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's take a copy from our data frames to work on cleaning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned = df_arch.copy()\n",
    "image_prediction_cleaned = image_prediction.copy()\n",
    "df_api_cleaned = df_api.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Replace 'None' with `np.nan` for Columns (`doggo`, `floofer`, `pupper`, `puppo`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "\n",
    "for col in col_list:\n",
    "    df_arch_cleaned[col] = df_arch_cleaned[col].replace('None', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Extract tweet source from `source` column using `apply` meth in pandas and convert it to categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the unique values\n",
    "df_arch_cleaned.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function fix_source which extract the strings between tags\n",
    "def fix_source(x):\n",
    "    'x is an html string from the source column in df_arch_cleaned dataset'\n",
    "    #find the first closed  tag >\n",
    "    i= x.find('>') + 1\n",
    "    # find the first open tag after the previous <\n",
    "    j =x[i:].find('<')\n",
    "    # extract the text in between\n",
    "    return x[i:][:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.source = df_arch_cleaned.source.apply(lambda x: fix_source(x)).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the unique values\n",
    "df_arch_cleaned.source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Extract rating scores correctly from tweet text using RegEx and convert it to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned[df_arch_cleaned.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")][['text', 'rating_numerator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ratings = df_arch_cleaned[df_arch_cleaned.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]['text'].str.extract(r\"(\\d+\\.\\d*(?=\\/\\d+))\")\n",
    "new_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.loc[new_ratings.index, 'rating_numerator'] = new_ratings.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.rating_numerator = df_arch_cleaned.rating_numerator.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arch_cleaned.loc[new_ratings.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_arch_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Remove ratings and links from `text` column using `RegEx`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.text = df_arch_cleaned.text.str.extract('(.+(?=\\s\\d+/\\d+\\s))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.text.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Converte `timestamp` column to datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.timestamp = pd.to_datetime(df_arch_cleaned.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.timestamp.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Remove values other than 10 for `rating_denominator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned = df_arch_cleaned[df_arch_cleaned['rating_denominator'] == 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned[['rating_numerator', 'rating_denominator']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Remove any rows not related to dogs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned = df_arch_cleaned[~df_arch_cleaned.text.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned = df_arch_cleaned.loc[~df_arch_cleaned.text.str.match('.*only rate dogs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.loc[df_arch_cleaned.text.str.match('.*only rate dogs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Drop rows with NaNs for `expanded_urls` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned = df_arch_cleaned.loc[~df_arch_cleaned.expanded_urls.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Create `dog_stage` column and remove the (`doggo`, `floofer`, `pupper`, `puppo`) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dog stages columns from the dataset\n",
    "cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "\n",
    "# create the dog_stage column with joining the four columns in one column dog_stage join for more than stage\n",
    "df_arch_cleaned['dog_stage'] = df_arch_cleaned[cols].\\\n",
    "                                        apply(lambda x: ', '.join(x.dropna().astype(str)),axis =1)\n",
    "# replace the empty string with nan and change datatype to category\n",
    "df_arch_cleaned.dog_stage = df_arch_cleaned.dog_stage.replace('', np.nan).astype('category')\n",
    "\n",
    "# drop the 4 columns\n",
    "df_arch_cleaned = df_arch_cleaned.drop(columns = cols, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "- Replace 'None' with np.name in df_arch `name` column.\n",
    "- Remove any rows with invalid names which starts with lower laters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned[~df_arch_cleaned.name.str.istitle()].name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.name.replace(['such', 'a', 'quite', 'not', 'one', 'incredibly', 'mad',\n",
    "       'an', 'very', 'just', 'my', 'his', 'actually', 'getting',\n",
    "       'this', 'unacceptable', 'all', 'old', 'infuriating', 'the',\n",
    "       'by', 'officially', 'life', 'light', 'space', 'None'], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arch_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "- Remove `img_num` column from image_prediction_cleand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_cleaned.drop('img_num', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Create `breed` and `confidence` columns with highest confidence predictions and drop other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed = []\n",
    "confidence = []\n",
    "# iterating over image_prediction row by row and taking the highest confident prediction other wise np.nan\n",
    "for index, row in image_prediction_cleaned.iterrows():\n",
    "    if row['p1_dog'] and row['p1_conf'] == max([row['p1_conf'], row['p2_conf'], row['p3_conf']]):\n",
    "        breed.append(row['p1'])\n",
    "        confidence.append(row['p1_conf'])\n",
    "    elif row['p2_dog'] and row['p2_conf'] == max([row['p1_conf'], row['p2_conf'], row['p3_conf']]):\n",
    "        breed.append(row['p2'])\n",
    "        confidence.append(row['p2_conf'])\n",
    "    elif row['p3_dog'] and row['p3_conf'] == max([row['p1_conf'], row['p2_conf'], row['p3_conf']]):\n",
    "        breed.append(row['p3'])\n",
    "        confidence.append(row['p3_conf'])\n",
    "    else:\n",
    "        breed.append(np.nan)\n",
    "        confidence.append(np.nan)\n",
    "        \n",
    "image_prediction_cleaned['breed'] = breed\n",
    "image_prediction_cleaned['confidence'] = confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_cleaned = image_prediction_cleaned[['tweet_id', 'jpg_url', 'breed', 'confidence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_prediction_cleaned.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Remove unnecessary columns for df_api_cleand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_cleaned = df_api_cleaned[['id', 'retweet_count', 'favorite_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "Rename `id` column in df_api_cleand to `tweet_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_cleaned.columns = ['tweet_id', 'retweet_count', 'favorite_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "- merge data into database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_arch_cleaned, image_prediction_cleaned, on=['tweet_id'], how='inner')\n",
    "df_merge = pd.merge(df_merge, df_api_cleaned, on = 'tweet_id', how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulate the value of 'rating'\n",
    "df_merge['rating'] = df_merge['rating_numerator'] / df_merge['rating_denominator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STORING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('archive_master_new.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangled_df= pd.read_csv('archive_master_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangled_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this list of dogs for rating > 2\n",
    "wrangled_df.loc[wrangled_df['rating'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wrangled_df.rating_numerator.value_counts()\n",
    "\n",
    "x = data.index\n",
    "y = data.values\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "g = sns.barplot(x, y, palette='Blues_d', ax=ax)\n",
    "ax.set(xlabel='Ratings', ylabel='Frequency', title='Ratings frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wrangled_df.rating_numerator.value_counts()\n",
    "\n",
    "ax = sns.boxplot(data, orient='v', width=.4)\n",
    "ax.set(xlabel='Ratings', ylabel='Frequency', title='Ratings frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that their are 2 outliers here so let's investigate more and check their data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df = wrangled_df[wrangled_df.rating_numerator > 400][['rating_numerator', 'name', 'jpg_url', 'text']]\n",
    "outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "fig=plt.figure()\n",
    "c = 1\n",
    "for index, row in outliers_df.iterrows():\n",
    "    r = requests.get(row['jpg_url'])\n",
    "    i = Image.open(BytesIO(r.content))\n",
    "    i.save('image2/' +  str(index) + '_' + str(row['rating_numerator']) + \"_\" + str(row['name']) + '.jpg')\n",
    "    fig.add_subplot(1, 2, c)\n",
    "    c += 1\n",
    "    plt.imshow(i)\n",
    "    plt.axis(\"0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "- So we can see here that the picture with 1776 rating is simply very cute dog and has the best rating score but the other pic with 420 rating score is the rap star Snoop Dogg and should be removed from our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Snoop Dogg' from our wrangled data\n",
    "wrangled_df.drop(index=1552, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangled_df.query('rating_numerator == 420')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangled_df.rating_numerator.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next we can look for the relation betwee 'retweet_count' and 'favorite_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot to show the relation between favorits and retweets\n",
    "ax = sns.regplot(x='retweet_count', y='favorite_count', data=wrangled_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(x='retweet_count', y='favorite_count', data=wrangled_df, color='b', scatter_kws={'s':5, 'alpha':.3}) \n",
    "ax.set(xlabel='Retweet count', ylabel='Favorite count', title='Favorits VS Retweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected the favorite and retweets are highly postive correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's compare dog stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wrangled_df.groupby('dog_stage').count()['tweet_id']\n",
    "ax = sns.barplot(y=data.index, x=data.values, palette='Blues_d')\n",
    "ax.set(xlabel='Count', ylabel='Dog stage', title='Dog Stage Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the most common stage is pupper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing tweets different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wrangled_df.groupby('source').count()['tweet_id']\n",
    "ax = sns.barplot(y=data.index, x=data.values, palette='Blues_d')\n",
    "ax.set(xlabel='Count', ylabel='Tweet source', title='Tweet Source Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we see here they tweeted the most from iPhone "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create a funny world cloud from our tweets text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(tweet for tweet in wrangled_df.text)\n",
    "print (\"There are {} words in the combination of all review.\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open('images/mask.jpeg'))\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['look', 'tho', 'see', 'good', 'hello', 'day', 'say', 'Meet'])\n",
    "wordcloud = WordCloud( max_words=500, stopwords=stopwords, \n",
    "                      background_color='white', contour_color='black', mask=mask).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('images/world_cloud.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
